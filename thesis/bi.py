import os
import re
import math
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# ===================== Config / Helpers =====================

OUT_DIR = "./bi"
os.makedirs(OUT_DIR, exist_ok=True)

SIZE_ORDER_ALIASES = {
    "small": 1, "medium": 2, "large": 3,
    "pequeno": 1, "medio": 2, "grande": 3
}

# Paleta vibrante e bem distinta
COLORS_VIBRANT = [
    "#007bff",  # blue
    "#ff3b30",  # red
    "#34c759",  # green
    "#ff9500",  # orange
    "#af52de",  # purple
    "#32ade6",  # cyan
    "#ff2d55",  # magenta/pink
    "#ffcc00",  # yellow
]

EXACT_NAMES = {"exato","exact","√≥timo","otimo","optimal","dp","backtracking","branch_and_bound","knapsack_exato"}
APPROX_NAMES = {"guloso","greedy","heuristica","heur√≠stica","approx","aproximado","knapsack_guloso"}

def parse_k_suffix(x: str):
    """Converte '1k' -> 1000, '10k'->10000; n√∫meros puros viram int; fallbacks mant√™m string."""
    try:
        s = str(x).strip().lower()
        if s.endswith('k'):
            return int(float(s[:-1]) * 1000)
        return int(float(s))
    except Exception:
        return None

def size_sort_key(v):
    """Ordena tamanhos: tenta n√∫mero; sen√£o usa aliases; sen√£o por string."""
    n = parse_k_suffix(v)
    if n is not None:
        return (0, n)
    rank = SIZE_ORDER_ALIASES.get(str(v).lower())
    if rank is not None:
        return (1, rank)
    return (2, str(v))

def ensure_monotonic_size_index(df):
    """Ordena index de tamanhos em ordem l√≥gica (1k, 10k, 100k / small, medium, large)."""
    ordered = sorted(df.index.unique(), key=size_sort_key)
    return df.reindex(ordered)

def savefig_simple(path):
    # para gr√°ficos sem tabela
    plt.tight_layout()
    plt.savefig(path, dpi=120)
    plt.clf()

def savefig_with_table(path):
    # para gr√°ficos com tabela (evita corte)
    plt.savefig(path, dpi=120, bbox_inches='tight', pad_inches=0.6)
    plt.clf()

def plot_error_lines(mean_df: pd.DataFrame, std_df: pd.DataFrame, title: str, ylabel: str, filename: str, xlabel="Tamanho do dataset"):
    if mean_df.empty:
        return

    mean_df = ensure_monotonic_size_index(mean_df)
    std_df = std_df.reindex(mean_df.index) if std_df is not None else None

    # cores
    cols = list(mean_df.columns)
    color_map = {col: COLORS_VIBRANT[i % len(COLORS_VIBRANT)] for i, col in enumerate(cols)}

    # ---- tamanho din√¢mico da figura ----
    n_rows = len(mean_df.index)
    base_plot_h = 6.0
    extra_per_row = 0.35
    fig_h = base_plot_h + extra_per_row * max(0, n_rows - 1)

    plt.figure(figsize=(12, fig_h))
    x = np.arange(len(mean_df.index))

    # plota s√©ries
    for col in cols:
        y = mean_df[col].values
        yerr = std_df[col].values if (std_df is not None and col in std_df.columns) else None
        c = color_map[col]
        plt.errorbar(
            x, y, yerr=yerr,
            fmt='-o', markersize=5, linewidth=1.8,
            color=c, ecolor=c, elinewidth=1, capsize=4,
            markeredgecolor="#ffffff", markeredgewidth=0.6,
            label=str(col)
        )

    plt.title(title)
    plt.ylabel(ylabel)
    plt.xlabel(xlabel)
    plt.xticks(x, [str(v) for v in mean_df.index], rotation=0)
    plt.grid(True, axis='y', alpha=0.25, linewidth=0.8)
    plt.legend(title="S√©ries", ncol=2)

    # ---- tabela com valores ¬± desvio ----
    if std_df is not None and not std_df.empty:
        table_df = mean_df.round(2).astype(str) + " ¬± " + std_df.fillna(0.0).round(2).astype(str)
    else:
        table_df = mean_df.round(2)

    csv_path = os.path.join(OUT_DIR, f"{filename}_tabela.csv")
    table_df.to_csv(csv_path)

    header = ["Tamanho"] + [str(c) for c in table_df.columns]
    rows = [[str(idx)] + [str(table_df.loc[idx, c]) for c in table_df.columns] for idx in table_df.index]
    header_colors = ["#f0f0f0"] + [color_map[c] for c in table_df.columns]

    # muito mais espa√ßo entre gr√°fico e tabela
    tbl_h = min(0.55, 0.18 + 0.05 * n_rows)
    tbl_y = -tbl_h - 0.25   # empurra bem para baixo

    table = plt.table(
        cellText=rows,
        colLabels=header,
        cellLoc='center',
        colColours=header_colors,
        loc='bottom',
        bbox=[0.0, tbl_y, 1.0, tbl_h],
    )
    table.auto_set_font_size(False)
    table.set_fontsize(9)
    table.scale(1.0, 1.15)

    for (_, cell) in table.get_celld().items():
        cell.set_linewidth(0.6)

    # margem inferior bem maior
    plt.subplots_adjust(left=0.08, right=0.98, top=0.88, bottom=0.55)

    plt.savefig(os.path.join(OUT_DIR, f"{filename}.png"), dpi=120, bbox_inches='tight', pad_inches=1.2)
    plt.clf()


def group_keys(df: pd.DataFrame, base=("linguagem","tamanho")):
    keys = [k for k in base if k in df.columns]
    # Adiciona 'algoritmo' e 'classe' se existirem (√∫teis p/ fatiar depois)
    for opt in ("algoritmo","classe"):
        if opt in df.columns and opt not in keys:
            keys.append(opt)
    return keys

# ===================== Load & Clean =====================

df = pd.read_json("./resultados/metricas.json")
df = df[df.get("tempo_s", 0) > 0].copy()

# Normaliza alguns nomes (opcional)
if "algoritmo" in df.columns:
    df["algoritmo_norm"] = df["algoritmo"].astype(str).str.strip().str.lower()
else:
    df["algoritmo_norm"] = np.nan

# ===================== Agrega√ß√µes (m√©dia, desvio, n) =====================

keys = group_keys(df, base=("linguagem","tamanho"))
metrics = {
    "tempo_s": ["mean","std","count"],
    "cpu_avg_during": ["mean","std","count"] if "cpu_avg_during" in df.columns else [],
    "ram_avg_during_mb": ["mean","std","count"] if "ram_avg_during_mb" in df.columns else [],
}
# Remove m√©tricas ausentes
metrics = {k:v for k,v in metrics.items() if len(v)>0}

agg = df.groupby(keys).agg(metrics)
# Achata MultiIndex de colunas
agg.columns = ["_".join([c for c in tup if c]) for tup in agg.columns.to_flat_index()]
agg = agg.reset_index()
agg.to_csv(os.path.join(OUT_DIR, "resumo_agg.csv"), index=False)

# ===================== Gr√°ficos principais com barras de erro =====================

def pivot_mean_std(agg: pd.DataFrame, value_prefix: str, index_col="tamanho", column_col="linguagem", extra_filters=None):
    sub = agg.copy()
    if extra_filters:
        for k, v in extra_filters.items():
            sub = sub[sub[k] == v]

    # üëá garante unicidade agregando por (index_col, column_col)
    cols_keep = [index_col, column_col, f"{value_prefix}_mean", f"{value_prefix}_std"]
    sub = (sub[cols_keep]
           .groupby([index_col, column_col], as_index=False)
           .agg({f"{value_prefix}_mean": "mean",  # m√©dia das m√©dias
                 f"{value_prefix}_std": "mean"})) # m√©dia dos desvios (ok p/ visual)

    # pivot seguro
    m = sub.pivot_table(index=index_col, columns=column_col, values=f"{value_prefix}_mean", aggfunc="mean")
    s = sub.pivot_table(index=index_col, columns=column_col, values=f"{value_prefix}_std",  aggfunc="mean")

    m = m.fillna(0)
    s = s.fillna(0)
    return m, s

# Tempo vs Tamanho (todas as linguagens)
m, s = pivot_mean_std(agg, "tempo_s", index_col="tamanho", column_col="linguagem")
plot_error_lines(m, s, "Tempo de Execu√ß√£o √ó Tamanho (todas as linguagens)", "Tempo (s)", "tempo_vs_tamanho_all")

# CPU vs Tamanho (se dispon√≠vel)
if "cpu_avg_during_mean" in agg.columns:
    m, s = pivot_mean_std(agg, "cpu_avg_during", index_col="tamanho", column_col="linguagem")
    plot_error_lines(m, s, "CPU m√©dia √ó Tamanho (todas as linguagens)", "CPU m√©dia (%)", "cpu_vs_tamanho_all")

# RAM vs Tamanho (se dispon√≠vel)
if "ram_avg_during_mb_mean" in agg.columns:
    m, s = pivot_mean_std(agg, "ram_avg_during_mb", index_col="tamanho", column_col="linguagem")
    plot_error_lines(m, s, "RAM m√©dia √ó Tamanho (todas as linguagens)", "RAM (MB)", "ram_vs_tamanho_all")

# ===================== Gr√°ficos por linguagem/algoritmo (um por arquivo) =====================

def plot_per_group(agg: pd.DataFrame, value_prefix: str, group_col: str, title_prefix: str, fname_prefix: str):
    if group_col not in agg.columns:
        return

    ylabel_map = {"tempo_s": "Tempo (s)", "cpu_avg_during": "CPU m√©dia (%)", "ram_avg_during_mb": "RAM (MB)"}
    ylabel = ylabel_map.get(value_prefix, value_prefix)

    for g in sorted(agg[group_col].dropna().unique()):
        sub = agg[agg[group_col] == g]
        if sub.empty:
            continue

        # Eixo X ser√° tamanho; as s√©ries (colunas) variam conforme o group_col
        if group_col != "linguagem" and "linguagem" in sub.columns:
            series_col = "linguagem"
        elif group_col != "algoritmo" and "algoritmo" in sub.columns:
            series_col = "algoritmo"
        elif group_col != "classe" and "classe" in sub.columns:
            series_col = "classe"
        else:
            # fallback: tudo em uma s√©rie √∫nica
            series_col = group_col

        # Agrega por (tamanho, series_col) p/ garantir unicidade
        needed = ["tamanho", series_col, f"{value_prefix}_mean", f"{value_prefix}_std"]
        needed = [c for c in needed if c in sub.columns]
        if len(needed) < 3:
            continue

        sub2 = (sub[needed]
                .groupby(["tamanho", series_col], as_index=False)
                .agg({f"{value_prefix}_mean": "mean", f"{value_prefix}_std": "mean"}))

        m = sub2.pivot_table(index="tamanho", columns=series_col, values=f"{value_prefix}_mean", aggfunc="mean")
        s = sub2.pivot_table(index="tamanho", columns=series_col, values=f"{value_prefix}_std",  aggfunc="mean")

        if m is None or m.empty:
            continue

        title = f"{title_prefix} ‚Äì {group_col}: {g}"
        fname = f"{fname_prefix}_{group_col}_{str(g)}"
        plot_error_lines(m, s, title, ylabel=ylabel, filename=fname)

# Por linguagem: como RAM e Tempo escalam com tamanho
plot_per_group(agg, "tempo_s", "linguagem", "Tempo √ó Tamanho", "tempo_vs_tamanho")
if "ram_avg_during_mb_mean" in agg.columns:
    plot_per_group(agg, "ram_avg_during_mb", "linguagem", "RAM √ó Tamanho", "ram_vs_tamanho")

# ===================== Linhas de c√≥digo =====================

if "linhas_codigo" in df.columns:
    loc_media = df.groupby("linguagem")["linhas_codigo"].mean().sort_values()
    loc_media.to_csv(os.path.join(OUT_DIR, "tabela_linhas_codigo_media_por_linguagem.csv"))
    ax = loc_media.plot(kind="bar", figsize=(10,6), title="M√©dia de linhas de c√≥digo por linguagem")
    plt.ylabel("Linhas de c√≥digo")
    plt.xlabel("Linguagem")
    for c in ax.containers:
        ax.bar_label(c, fmt="%.0f", fontsize=8)
    savefig_simple(os.path.join(OUT_DIR, "linhas_codigo_por_linguagem.png"))

    if "classe" in df.columns:
        loc_lang_cls = df.groupby(["linguagem","classe"])["linhas_codigo"].mean().unstack().fillna(0)
        loc_lang_cls.to_csv(os.path.join(OUT_DIR, "tabela_linhas_codigo_linguagem_classe.csv"))
        ax = loc_lang_cls.plot(kind="bar", figsize=(10,6), title="M√©dia de linhas de c√≥digo por linguagem e classe")
        plt.ylabel("Linhas de c√≥digo")
        plt.xlabel("Linguagem")
        plt.xticks(rotation=45)
        for c in ax.containers:
            ax.bar_label(c, fmt="%.0f", fontsize=8)
        savefig_simple(os.path.join(OUT_DIR, "linhas_codigo_linguagem_classe.png"))

# ===================== Knapsack: exato vs guloso (tempo/CPU/RAM) nos menores datasets =====================

def is_knapsack_row(row):
    # tenta identificar knapsack por classe ou campos extras
    if str(row.get("problema","")).lower() == "knapsack":
        return True
    if str(row.get("classe","")).lower() in {"np-completo","np completo","np_completo"}:
        # opcional: se voc√™ marcar no JSON um campo problema="knapsack", melhor.
        # Aqui mantemos generoso: muitos dos seus 'np-completo' s√£o Knapsack.
        return True
    return False

if "tamanho" in df.columns:
    knap = df[df.apply(is_knapsack_row, axis=1)].copy()
    if not knap.empty and "algoritmo_norm" in knap.columns:
        # Identifica menores tamanhos (pegar os 2 mais baixos)
        sizes_sorted = sorted(knap["tamanho"].unique(), key=size_sort_key)
        menores = sizes_sorted[:2] if len(sizes_sorted) >= 2 else sizes_sorted
        knap_small = knap[knap["tamanho"].isin(menores)].copy()

        # Marca tipo (exato vs guloso) a partir do nome do algoritmo
        def tipo_alg(s):
            s = str(s).lower()
            if any(name in s for name in EXACT_NAMES):
                return "exato"
            if any(name in s for name in APPROX_NAMES):
                return "guloso"
            return np.nan
        if "algoritmo" in knap_small.columns:
            knap_small["tipo"] = knap_small["algoritmo"].apply(tipo_alg)
        else:
            knap_small["tipo"] = np.nan

        # Se n√£o conseguirmos identificar, n√£o plota
        if knap_small["tipo"].notna().any():
            keys_knap = [k for k in ("linguagem","tamanho","tipo") if k in knap_small.columns]
            agg_knap = knap_small.groupby(keys_knap).agg({
                k: ["mean","std","count"] for k in ["tempo_s"] 
                if k in knap_small.columns
            })
            if "cpu_avg_during" in knap_small.columns:
                agg_c = knap_small.groupby(keys_knap)["cpu_avg_during"].agg(["mean","std","count"])
                agg_knap[("cpu_avg_during","mean")] = agg_c["mean"]
                agg_knap[("cpu_avg_during","std")] = agg_c["std"]
                agg_knap[("cpu_avg_during","count")] = agg_c["count"]
            if "ram_avg_during_mb" in knap_small.columns:
                agg_r = knap_small.groupby(keys_knap)["ram_avg_during_mb"].agg(["mean","std","count"])
                agg_knap[("ram_avg_during_mb","mean")] = agg_r["mean"]
                agg_knap[("ram_avg_during_mb","std")] = agg_r["std"]
                agg_knap[("ram_avg_during_mb","count")] = agg_r["count"]

            agg_knap.columns = ["_".join([c for c in tup if c]) for tup in agg_knap.columns.to_flat_index()]
            agg_knap = agg_knap.reset_index()
            agg_knap.to_csv(os.path.join(OUT_DIR, "knapsack_small_exato_vs_guloso.csv"), index=False)

            # Para cada linguagem, tempo/CPU/RAM vs tamanho comparando exato x guloso
            for lang in sorted(agg_knap["linguagem"].unique()):
                sub = agg_knap[agg_knap["linguagem"]==lang]
                if sub.empty: 
                    continue

                def piv(v):
                    m = sub.pivot(index="tamanho", columns="tipo", values=f"{v}_mean").fillna(0)
                    s = sub.pivot(index="tamanho", columns="tipo", values=f"{v}_std").fillna(0)
                    return m, s

                if "tempo_s_mean" in sub.columns:
                    m,s = piv("tempo_s")
                    plot_error_lines(m, s, f"Knapsack (Exato vs Guloso) ‚Äì Tempo ‚Äì {lang}", "Tempo (s)", f"knapsack_tempo_{lang}")

                if "cpu_avg_during_mean" in sub.columns:
                    m,s = piv("cpu_avg_during")
                    plot_error_lines(m, s, f"Knapsack (Exato vs Guloso) ‚Äì CPU ‚Äì {lang}", "CPU m√©dia (%)", f"knapsack_cpu_{lang}")

                if "ram_avg_during_mb_mean" in sub.columns:
                    m,s = piv("ram_avg_during_mb")
                    plot_error_lines(m, s, f"Knapsack (Exato vs Guloso) ‚Äì RAM ‚Äì {lang}", "RAM (MB)", f"knapsack_ram_{lang}")

# ===================== (Opcional) Qualidade da solu√ß√£o da heur√≠stica =====================
# Para calcular qualidade, ideal ter:
# - uma coluna identificando a inst√¢ncia/caso (ex: 'instancia' ou 'dataset_id')
# - 'valor_objetivo' (valor obtido) para cada execu√ß√£o
# - para os casos com algoritmo exato, o 'valor_otimo' da MESMA inst√¢ncia
#
# Se voc√™ expor isso no JSON, podemos fazer: qualidade = valor_heuristica / valor_otimo

def compute_solution_quality(df_knap: pd.DataFrame):
    cols_case = [c for c in ("instancia","dataset_id","caso_id","arquivo","dataset_nome") if c in df_knap.columns]
    if not cols_case:
        print("[INFO] Para qualidade da solu√ß√£o, adicione uma coluna de identifica√ß√£o de caso (ex: 'instancia').")
        return pd.DataFrame()

    case_col = cols_case[0]

    if not {"valor_objetivo","algoritmo_norm",case_col}.issubset(df_knap.columns):
        print("[INFO] Para qualidade da solu√ß√£o, adicione 'valor_objetivo' (num√©rico) e 'algoritmo'.")
        return pd.DataFrame()

    exato = df_knap[df_knap["algoritmo_norm"].isin(EXACT_NAMES)][[case_col,"valor_objetivo"]].rename(columns={"valor_objetivo":"valor_otimo"})
    heur = df_knap[df_knap["algoritmo_norm"].isin(APPROX_NAMES)][[case_col,"valor_objetivo","linguagem","tamanho"]]

    merged = pd.merge(heur, exato, on=case_col, how="inner")
    if merged.empty:
        print("[INFO] N√£o foi poss√≠vel casar heur√≠stica com exato. Verifique 'instancia'/'dataset_id'.")
        return pd.DataFrame()

    merged["qualidade"] = merged["valor_objetivo"] / merged["valor_otimo"]
    # Agrega por linguagem/tamanho para plot
    q = merged.groupby(["linguagem","tamanho"])["qualidade"].agg(["mean","std","count"]).reset_index()
    q.to_csv(os.path.join(OUT_DIR, "knapsack_qualidade.csv"), index=False)

    # Plota qualidade (quanto mais perto de 1.0, melhor)
    m = q.pivot(index="tamanho", columns="linguagem", values="mean").fillna(np.nan)
    s = q.pivot(index="tamanho", columns="linguagem", values="std").fillna(0.0)
    plot_error_lines(m, s, "Qualidade da solu√ß√£o (Heur√≠stica/√ìtimo) ‚Äì Knapsack", "Raz√£o (‚Üë melhor)", "knapsack_qualidade")
    return merged

# Descomente quando tiver 'valor_objetivo' e identificador de inst√¢ncia no JSON:
# if not knap.empty:
#     compute_solution_quality(knap)
