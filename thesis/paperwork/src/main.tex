\documentclass[12pt, a4paper]{article}
\usepackage[lmargin=3cm,rmargin=2cm,tmargin=3cm,bmargin=2cm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{titling}
\usepackage[brazil]{babel}
\usepackage{enumerate,setspace,graphicx,amsmath,tikz,amsfonts,amssymb}
\usepackage{indentfirst}
\usepackage{times}
\usepackage{color}
\usepackage{hyperref}
\usepackage[alf]{abntex2cite}
\usepackage{url}
\usepackage{float}
\usepackage[skip=10pt]{caption}

% Formatação do artigo
\onehalfspacing
\setlength{\parindent}{1.25cm}
\setlength{\parskip}{0.2cm}

% Configurações do título e autores
\pretitle{\raggedright\large\bfseries}
\posttitle{\par\vspace{0.1em}}
\preauthor{\raggedright\small}
\postauthor{\par\vspace{-5em}}

% Título e autores
\title{Avaliação Comparativa de Algoritmos em Diferentes Linguagens de Programação: Impacto no Desempenho e Eficiência Computacional}
\author{Guilherme Cavenaghi (Fundação Hermínio Ometto) guilherme.cavenaghi@alunos.fho.edu.br
Renato Luciano Cagnin (Fundação Hermínio Ometto) renato\_cagnin@fho.edu.br}
\date{}

\begin{document}
\pagenumbering{gobble}
\maketitle

% Resumo alinhado à esquerda
\begin{flushleft}
\section*{Resumo}
\noindent Este trabalho apresenta uma análise comparativa de desempenho de algoritmos de classes polinomiais implementados em múltiplas linguagens de programação. O estudo busca avaliar métricas como tempo de execução, uso de memória e complexidade de implementação, considerando diferentes paradigmas de execução e modelos de tipagem. A investigação tem como objetivo identificar potenciais impactos da linguagem de programação na eficiência computacional, fornecendo subsídios para decisões fundamentadas em contextos de desenvolvimento e pesquisa. A abordagem adotada inclui experimentos controlados e repetidos para garantir confiabilidade estatística, permitindo a comparação rigorosa entre as linguagens avaliadas. Espera-se, com isso, contribuir para o entendimento do papel das linguagens de programação no desempenho de algoritmos, orientando escolhas tecnológicas em projetos computacionais de diferentes naturezas.

\vspace{0.15cm}
\noindent\textbf{Palavras-chave:} algoritmos, linguagens de programação, desempenho computacional, análise de complexidade, eficiência de execução.
\end{flushleft}


% 1. Introdução
\section{Introdução}
O desenvolvimento de software de alta qualidade e desempenho constitui um aspecto central da computação, uma vez que a eficiência computacional afeta diretamente o tempo de execução, o consumo de recursos e a escalabilidade das aplicações. Nesse contexto, a escolha da linguagem de programação emerge como uma variável determinante, influenciando a forma como algoritmos são implementados e executados, impactando, consequentemente, o desempenho geral dos sistemas. Embora a lógica algorítmica seja, em essência, independente da linguagem, fatores como modelo de execução (interpretado ou compilado), gerenciamento de memória (manual ou automático), tipagem (estática ou dinâmica) e otimizações aplicadas pelos compiladores ou interpretadores introduzem variações significativas no comportamento prático dos algoritmos, como destaca \citeonline{sebesta2016}.

Apesar da reconhecida importância desse tema, observa-se na literatura uma lacuna no que diz respeito a estudos empíricos que abordem comparativamente o impacto das linguagens de programação no desempenho de algoritmos. A maioria dos trabalhos existentes limita-se a análises conceituais ou relatos de experiências pontuais, carecendo de experimentação controlada e de dados quantitativos robustos que permitam fundamentar decisões de escolha de linguagem em cenários computacionais diversos. Tal lacuna evidencia a necessidade de investigações sistemáticas que transcendam discussões meramente subjetivas e contribuam para a consolidação do conhecimento científico na área.

A relevância desta pesquisa decorre, portanto, da necessidade de orientar desenvolvedores e pesquisadores na seleção mais adequada de linguagens de programação, considerando não apenas critérios subjetivos de preferência ou familiaridade, mas também evidências empíricas de desempenho, uso de memória e complexidade de implementação. Essa fundamentação é especialmente importante em aplicações críticas que demandam alto desempenho e confiabilidade, impactando diretamente a produtividade e a eficiência dos sistemas de software.

A motivação central deste trabalho reside na percepção de que, em um cenário de crescente diversidade de linguagens de programação e de demandas por eficiência, torna-se imperativo compreender como diferentes linguagens se comportam na implementação de algoritmos fundamentais. Tal compreensão possibilita não apenas a escolha racional de tecnologias, mas também a identificação de trade-offs relevantes entre desempenho e produtividade, contribuindo para o aprimoramento da qualidade de projetos de software em ambientes acadêmicos e industriais.

Diante desse panorama, este trabalho tem como objetivo principal realizar uma análise comparativa do desempenho de algoritmos clássicos pertencentes à classe polinomial, considerando diferentes linguagens de programação. Busca-se, assim, fornecer uma base empírica que auxilie na tomada de decisões fundamentadas acerca da escolha de linguagem, considerando o impacto de diferentes paradigmas de execução e características de implementação no desempenho computacional.

\section{Referencial Teórico}

\subsection{Teoria da Complexidade Computacional}

A teoria da complexidade computacional estuda a classificação de problemas de acordo com os recursos necessários para resolvê-los, como tempo e memória. Essa classificação é essencial para compreender as limitações práticas e teóricas na execução de algoritmos e fundamenta a análise comparativa de linguagens de programação.  

\subsubsection{Modelos de Computação}

O modelo de máquina de Turing é a base teórica para definição de complexidade, permitindo a formalização de algoritmos e problemas computacionais. Para um problema de decisão, define-se \( T(n) \) como a função de tempo que representa o número de passos que a máquina executa para resolver o problema de entrada de tamanho \( n \).

\subsubsection{Classes de Complexidade Polinomial}

Neste trabalho, o foco recai sobre as classes de complexidade polinomial, fundamentais para a análise comparativa de desempenho computacional. A Figura~\ref{fig:complexidade} ilustra as principais relações entre essas classes de complexidade. São elas:

\begin{itemize}
    \item \textbf{Classe P}: Inclui problemas solucionáveis por algoritmos determinísticos em tempo polinomial. Formalmente:
    \[
    T(n) = O(n^k)
    \]
    para alguma constante \( k \). Essa classe representa problemas considerados tratáveis na prática, como o MergeSort (\( O(n \log n) \)) \citeonline{knuth1998}.

    \item \textbf{Classe NP}: Compreende problemas cujas soluções podem ser verificadas em tempo polinomial, mesmo que não exista algoritmo determinístico conhecido para resolvê-los em tempo polinomial. Para todo \( L \in \text{NP} \), existe um verificador determinístico \( V(x,y) \):
    \[
    V(x, y) = \text{Sim ou Não}
    \]
    com:
    \[
    T_V(|x| + |y|) = O((|x| + |y|)^k)
    \]
    Exemplo: Fatoração de inteiros (Factoring) \citeonline{rivest1978}.

    \item \textbf{Classe NP-completo}: Engloba problemas para os quais qualquer problema em NP pode ser reduzido a eles em tempo polinomial. Para \( A \) ser NP-completo:
    \[
    A \in \text{NP} \quad \text{e} \quad \forall B \in \text{NP}, \quad B \leq_P A
    \]
    onde \( B \leq_P A \) indica uma redução polinomial. Exemplo: Problema da Mochila (Knapsack) \citeonline{garey1979}.

    \item \textbf{Classe NP-difícil}: Abrange problemas que são no mínimo tão difíceis quanto qualquer problema de NP, podendo ser ou não verificáveis em tempo polinomial. Para \( A \) ser NP-difícil:
    \[
    \forall B \in \text{NP}, \quad B \leq_P A
    \]
    Muitos desses problemas são indecidíveis, como o Problema da Parada (Halting Problem), definido por:
    \[
    \text{HALT}(P,x) = 
    \begin{cases}
    \text{Sim}, & \text{se } P(x) \text{ termina} \\
    \text{Não}, & \text{caso contrário}
    \end{cases}
    \]
    O Teorema de Turing demonstra que HALT é indecidível, não existindo algoritmo que resolva o problema para todas as entradas \citeonline{sipser2012}.
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{img/relacaoDeConjuntos.png}
    \caption{Diagrama das classes de complexidade P, NP, NP-completo e NP-difícil.}
    \label{fig:complexidade}
\end{figure}
\subsection{Algoritmos Fundamentais}

Os algoritmos utilizados para análise de desempenho são representativos das classes polinomiais e foram escolhidos considerando sua relevância teórica e aplicabilidade prática.

\subsubsection{Ordenação}

O algoritmo MergeSort é representativo da classe P e é amplamente utilizado devido à sua complexidade \( O(n \log n) \). Sua estrutura de divisão e conquista permite uma ordenação eficiente, servindo como benchmark para linguagens de programação compiladas e interpretadas.

\subsubsection{Problemas de Otimização e Fatoração}

Problemas como o Knapsack (NP-completo) e o Factoring (NP) são utilizados para avaliar a capacidade das linguagens em lidar com desafios de verificação e busca combinatória.

\subsubsection{Problemas Indecidíveis}

A análise do Problema da Parada, apesar de ser indecidível em geral, é abordada de forma restrita neste trabalho (por exemplo, simulando programas com entradas controladas), possibilitando a avaliação de tempo de execução e uso de memória em linguagens diversas.

\subsection{Linguagens de Programação}

A linguagem de programação exerce impacto significativo na implementação de algoritmos, influenciando tempo de execução, uso de memória e complexidade de desenvolvimento.

\subsubsection{Critérios de Seleção}

As linguagens foram escolhidas com base em:

\begin{itemize}
    \item \textbf{Popularidade}: Métricas como o TIOBE Index \citeonline{tiobe}, GitHub Octoverse \citeonline{octoverse} e Stack Overflow Developer Survey \citeonline{stackoverflow}.
    \item \textbf{Diversidade de paradigmas}: Compiladas (C, C++, Rust), interpretadas (Python, JavaScript) e híbridas (Java, C\#, Go, Kotlin, TypeScript).
    \item \textbf{Aplicabilidade acadêmica e industrial}: Referências como Sebesta \citeonline{sebesta2016} evidenciam o uso prático e teórico das linguagens.
\end{itemize}

\subsubsection{Paradigmas e Modelos de Execução}

A diversidade de linguagens reflete diferenças como:

\begin{itemize}
    \item \textbf{Modelo de execução}: Compilado (execução direta) ou interpretado (via máquina virtual ou interpretador).
    \item \textbf{Tipagem}: Estática (C, Java) ou dinâmica (Python, JavaScript).
    \item \textbf{Gerenciamento de memória}: Manual (C, C++) ou automático (Java, Python).
\end{itemize}

Essas características influenciam diretamente o desempenho e a escalabilidade dos algoritmos, justificando a escolha das linguagens para os experimentos.


% 3. Materiais e Métodos
\section{Materiais e Métodos}

\subsection{Ambiente Experimental}

Os experimentos serão realizados em ambiente controlado, a fim de reduzir variações externas que possam interferir nas medições de desempenho. A configuração de hardware e software utilizada é a seguinte:

\begin{itemize}
    \item \textbf{Processador}: 11th Gen Intel(R) Core(TM) i7-1165G7 @ 2.80 GHz, com suporte a múltiplos threads, adequado para executar algoritmos em diferentes linguagens com boa capacidade computacional.
    \item \textbf{Memória RAM}: 16 GB DDR4 (2667 MHz), garantindo que a execução dos experimentos ocorra sem restrições de memória para os tamanhos de entrada definidos.
    \item \textbf{Placa de Vídeo}: Intel(R) Iris(R) Xe Graphics com 128 MB de memória dedicada, suficiente para suportar ambientes gráficos e alguns experimentos que exigem renderização leve.
    \item \textbf{Sistema Operacional}: Ubuntu 22.04 LTS, escolhido por sua estabilidade, suporte a múltiplas linguagens de programação e ferramentas robustas de monitoramento de desempenho.
\end{itemize}

Essa infraestrutura assegura uniformidade na execução dos algoritmos, minimizando influências externas como processos em segundo plano ou gerenciadores de energia.

\subsection{Métricas}

Para cada combinação de algoritmo e linguagem de programação, serão avaliadas as seguintes métricas:

\begin{itemize}
    \item \textbf{Tempo de Execução (Wall Clock Time)}: Medido como a média de 30 execuções consecutivas, utilizando o tempo de relógio total decorrido (e não apenas tempo de CPU). Essa métrica captura o tempo real de execução percebido pelo usuário, incluindo overheads do interpretador ou da máquina virtual.
    \item \textbf{Uso de Memória (RSS)}: Obtido a partir do utilitário \texttt{/usr/bin/time}, considerando o pico de uso de memória residente (Resident Set Size) durante a execução. Essa métrica reflete a demanda de memória real, incluindo buffers e alocações dinâmicas.
    \item \textbf{Complexidade de Implementação}: Avaliada por meio de Linhas de Código Fonte (SLOC) e Complexidade Ciclomática (McCabe). O SLOC fornece uma medida quantitativa da extensão do código-fonte, enquanto a Complexidade Ciclomática indica a quantidade de caminhos lógicos distintos, fornecendo uma proxy para a manutenção e legibilidade do algoritmo.
\end{itemize}

A escolha dessas métricas justifica-se pela necessidade de compreender não apenas o desempenho absoluto (tempo e memória), mas também o esforço de implementação associado a cada linguagem de programação.

\subsection{Conjuntos de Dados}

Serão utilizados conjuntos de dados sintéticos escaláveis, projetados para garantir reprodutibilidade e permitir análises comparativas em diferentes ordens de grandeza. Os tamanhos de entrada foram definidos com base na complexidade assintótica dos algoritmos implementados, respeitando a classe polinomial analisada no referencial teórico:

\begin{itemize}
    \item \textbf{Pequeno}: \( n = 10^3 \), representando cenários de entrada modestos, nos quais o overhead da linguagem pode ter impacto relevante.
    \item \textbf{Médio}: \( n = 10^4 \), para avaliar o comportamento intermediário e transições de eficiência entre linguagens compiladas e interpretadas.
    \item \textbf{Grande}: \( n = 10^5 \), simulando cargas intensivas de dados e testando a escalabilidade prática dos algoritmos implementados.
\end{itemize}

Cada conjunto de dados será gerado aleatoriamente, assegurando diversidade de instâncias e evitando vieses que possam privilegiar alguma linguagem específica.

\subsection{Procedimentos Experimentais}

Para cada linguagem de programação e algoritmo, o procedimento experimental será conduzido conforme os seguintes passos:

\begin{enumerate}
    \item Implementação dos algoritmos em todas as linguagens, utilizando boas práticas de codificação e bibliotecas padrão sempre que possível, para evitar otimizações artificiais.
    \item Compilação (para linguagens compiladas) ou configuração do interpretador (para linguagens interpretadas) com parâmetros padrão, garantindo uniformidade na execução.
    \item Execução dos testes de forma repetida (30 vezes) para cada tamanho de entrada, coletando as métricas definidas anteriormente.
    \item Armazenamento e análise estatística dos resultados, utilizando medidas de tendência central (média e mediana) e variabilidade (desvio padrão).
\end{enumerate}

% 4. Resultados
\section{Resultados}

Nesta seção são apresentados os resultados obtidos a partir da execução dos experimentos descritos anteriormente. As métricas avaliadas foram: tempo médio de execução, uso de memória, consumo de CPU e complexidade de implementação (linhas de código). Para cada combinação de linguagem, tamanho do dataset e algoritmo, os testes foram repetidos 30 vezes a fim de calcular média e desvio-padrão, assegurando maior robustez estatística.

\subsection{Tempo de Execução}

A Figura~\ref{fig:tempo_execucao} apresenta a evolução do tempo de execução em função do tamanho do dataset. Observa-se que os algoritmos de classes polinomiais mantêm desempenho estável mesmo em instâncias maiores, enquanto aqueles com maior complexidade apresentam crescimento mais acentuado. Os resultados confirmam a tendência teórica esperada.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{img/tempo_vs_tamanho_all.png}
    \caption{Tempo médio de execução em função do tamanho do dataset (geral, sem NP-Completo). Barras indicam o desvio-padrão.}
    \label{fig:tempo_execucao}
\end{figure}

\begin{table}[H]
    \centering
    \caption{Tempo médio de execução (em segundos) e desvio-padrão por linguagem e tamanho do dataset (geral, sem NP-Completo).}
    \label{tab:tempo_execucao_geral_sem_npcomp}
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{l|cc|cc|cc|cc|cc|cc|cc|cc|cc|cc|cc}
        \hline
        \textbf{Tamanho} & \multicolumn{2}{c|}{\textbf{C}} & \multicolumn{2}{c|}{\textbf{C\#}} & \multicolumn{2}{c|}{\textbf{C++}} & \multicolumn{2}{c|}{\textbf{Go}} & \multicolumn{2}{c|}{\textbf{Java}} & \multicolumn{2}{c|}{\textbf{JS}} & \multicolumn{2}{c|}{\textbf{Kotlin}} & \multicolumn{2}{c|}{\textbf{Python}} & \multicolumn{2}{c|}{\textbf{Rust}} & \multicolumn{2}{c}{\textbf{TS}} \\
        \hline
        & M & DP & M & DP & M & DP & M & DP & M & DP & M & DP & M & DP & M & DP & M & DP & M & DP \\
        \hline
        small  & 0.01 & 0.00 & 0.03 & 0.00 & 0.01 & 0.01 & 0.11 & 0.05 & 0.07 & 0.01 & 0.11 & 0.02 & 0.07 & 0.01 & 0.05 & 0.04 & 0.01 & 0.00 & 0.90 & 0.11 \\
        medium & 0.03 & 0.03 & 0.04 & 0.02 & 0.03 & 0.03 & 0.12 & 0.03 & 0.10 & 0.02 & 0.14 & 0.03 & 0.10 & 0.01 & 0.32 & 0.40 & 0.02 & 0.02 & 0.90 & 0.09 \\
        large  & 0.20 & 0.27 & 0.21 & 0.17 & 0.21 & 0.28 & 0.35 & 0.26 & 0.26 & 0.26 & 0.32 & 0.17 & 0.30 & 0.11 & 2.94 & 3.95 & 0.13 & 0.16 & 1.18 & 0.28 \\
        \hline
    \end{tabular}%
    }
\end{table}

\textbf{Conclusão parcial:} Linguagens compiladas de baixo nível (C, C++, Rust) apresentaram tempos mais consistentes e reduzidos. Python e TypeScript tiveram desempenho inferior, especialmente em instâncias grandes, confirmando a influência do modelo de execução interpretado.

\subsection{Uso de CPU}

A Figura~\ref{fig:cpu} mostra o consumo máximo de CPU normalizada durante as execuções. O aumento é mais pronunciado nos datasets maiores, indicando maior esforço computacional para manter os cálculos. Ainda assim, algumas linguagens mantiveram boa eficiência.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{img/cpu_vs_tamanho_all.png}
    \caption{Consumo máximo de CPU normalizada para cada tamanho de dataset.}
    \label{fig:cpu}
\end{figure}

\begin{table}[H]
    \centering
    \caption{Consumo máximo de CPU normalizada (\%) por linguagem e tamanho de dataset.}
    \label{tab:cpu}
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{l|cc|cc|cc|cc|cc|cc|cc|cc|cc|cc|cc}
        \hline
        \textbf{Tamanho} & \multicolumn{2}{c|}{\textbf{C}} & \multicolumn{2}{c|}{\textbf{C\#}} & \multicolumn{2}{c|}{\textbf{C++}} & \multicolumn{2}{c|}{\textbf{Go}} & \multicolumn{2}{c|}{\textbf{Java}} & \multicolumn{2}{c|}{\textbf{JS}} & \multicolumn{2}{c|}{\textbf{Kotlin}} & \multicolumn{2}{c|}{\textbf{Py}} & \multicolumn{2}{c|}{\textbf{Rust}} & \multicolumn{2}{c}{\textbf{TS}} \\
        & M & DP & M & DP & M & DP & M & DP & M & DP & M & DP & M & DP & M & DP & M & DP & M & DP \\
        \hline
        small  & 0.00 & 0.00 & 23.84 & 3.86 & 0.00 & 0.00 & 42.08 & 9.85 & 40.99 & 12.08 & 28.30 & 8.78 & 44.59 & 11.82 & 22.00 & 7.01 & 0.00 & 0.00 & 49.82 & 5.72 \\
        medium & 10.86 & 15.46 & 24.09 & 3.43 & 10.88 & 15.48 & 41.59 & 9.14 & 63.83 & 9.91 & 30.66 & 9.79 & 62.89 & 10.08 & 23.79 & 5.35 & 9.05 & 12.91 & 48.47 & 4.76 \\
        large  & 18.88 & 14.40 & 30.50 & 8.21 & 18.21 & 14.42 & 42.43 & 9.46 & 62.03 & 9.42 & 37.15 & 9.55 & 66.44 & 9.78 & 26.79 & 5.04 & 18.70 & 13.65 & 48.45 & 6.07 \\
        \hline
    \end{tabular}%
    }
\end{table}

\textbf{Conclusão parcial:} Linguagens como Go, Kotlin e Java apresentaram alto consumo de CPU em instâncias grandes, enquanto C e C++ mostraram uso mais eficiente. Python apresentou variação significativa, sugerindo menor controle sobre recursos.

\subsection{Uso de Memória}

O consumo de memória é apresentado na Figura~\ref{fig:memoria}. Verifica-se aumento gradual com o crescimento do dataset, sendo mais acentuado em linguagens com ambientes de execução mais pesados (Java, Kotlin, Rust, TypeScript).

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{img/ram_vs_tamanho_all.png}
    \caption{Uso máximo de memória em função do tamanho do dataset.}
    \label{fig:memoria}
\end{figure}

\begin{table}[H]
    \centering
    \caption{Uso máximo de memória (MB) e desvio padrão (DP).}
    \label{tab:memoria}
    \resizebox{\textwidth}{!}{%
        \begin{tabular}{c|cc|cc|cc|cc|cc|cc|cc|cc|cc|cc}
            \hline
            \textbf{Tamanho}
            & \multicolumn{2}{c|}{\textbf{C}}
            & \multicolumn{2}{c|}{\textbf{C\#}}
            & \multicolumn{2}{c|}{\textbf{C++}}
            & \multicolumn{2}{c|}{\textbf{Go}}
            & \multicolumn{2}{c|}{\textbf{Java}}
            & \multicolumn{2}{c|}{\textbf{JS}}
            & \multicolumn{2}{c|}{\textbf{Kotlin}}
            & \multicolumn{2}{c|}{\textbf{Py}}
            & \multicolumn{2}{c|}{\textbf{Rust}}
            & \multicolumn{2}{c}{\textbf{TS}} \\
            \cline{2-21}
            & M & DP & M & DP & M & DP & M & DP & M & DP & M & DP & M & DP & M & DP & M & DP & M & DP \\
            \hline
            small  & 0.68 & 0.29 & 18.08 & 0.81 & 0.48 & 0.06 & 48.23 & 1.51 & 43.65 & 0.80 & 49.80 & 1.70 & 45.66 & 0.87 & 9.90 & 0.41 & 0.58 & 0.30 & 76.78 & 1.29 \\
            medium & 1.35 & 0.94 & 19.92 & 1.25 & 1.65 & 1.66 & 48.52 & 1.46 & 50.76 & 1.62 & 50.92 & 2.22 & 55.87 & 5.43 & 11.12 & 0.79 & 1.09 & 0.75 & 76.78 & 0.82 \\
            large  & 1.85 & 0.86 & 33.97 & 2.18 & 6.58 & 1.86 & 48.13 & 1.49 & 67.30 & 4.80 & 65.73 & 9.21 & 93.35 & 25.56 & 24.76 & 8.39 & 2.44 & 1.46 & 89.03 & 6.27 \\
            \hline
        \end{tabular}%
    }
\end{table}

\textbf{Conclusão parcial:} Linguagens de baixo nível, como C e C++, demonstraram consumo mínimo de memória. Por outro lado, Java, Kotlin e TypeScript apresentaram maiores demandas, o que reflete o custo adicional de suas máquinas virtuais e runtime.

\subsection{Qualidade da Solução da Heurística}

Nos conjuntos menores (\(n = 10^3\) e \(n = 10^4\)), foi possível comparar diretamente o desempenho do algoritmo heurístico em relação ao exato. Observa-se que a heurística reduziu drasticamente o tempo de execução, com perda mínima de qualidade. Para o conjunto grande, apenas o heurístico pôde ser avaliado.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{img/qualidade_heuristica.png}
    \caption{Comparação de tempo de execução entre solução exata e heurística (NP-Completo).}
    \label{fig:qualidade}
\end{figure}

\begin{table}[H]
    \centering
    \caption{Comparação de tempo de execução entre solução exata e heurística (NP-Completo).}
    \label{tab:qualidade_np}
    \resizebox{0.8\textwidth}{!}{%
    \begin{tabular}{c|cc|cc}
        \hline
        \textbf{Tamanho} & \multicolumn{2}{c|}{\textbf{Exato}} & \multicolumn{2}{c}{\textbf{Heurístico (Guloso)}} \\
        \cline{2-5}
         & M (s) & DP (s) & M (s) & DP (s) \\
        \hline
        small  & 0.57 & 1.27 & 0.11 & 0.21 \\
        medium & 3.72 & 2.50 & 0.13 & 0.22 \\
        large  & -- & -- & 0.24 & 0.26 \\
        \hline
    \end{tabular}%
    }
\end{table}

\textbf{Conclusão parcial:} A heurística apresentou ganhos expressivos em tempo de execução, especialmente em datasets médios, sem comprometer significativamente a qualidade. O algoritmo exato tornou-se inviável em instâncias grandes.

\subsection{Linhas de Código}

A Figura~\ref{fig:sloc} e a Tabela~\ref{tab:sloc} apresentam a quantidade média de linhas de código (SLOC) necessárias para implementar cada algoritmo em cada linguagem. Essa métrica reflete a complexidade de implementação e serve de base para discutir o trade-off entre facilidade de desenvolvimento e desempenho.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{img/linhas_codigo_linguagem_algoritmo.png}
    \caption{Linhas de código (SLOC) médias por linguagem e algoritmo.}
    \label{fig:sloc}
\end{figure}

\begin{table}[H]
    \centering
    \caption{Linhas de código (SLOC) médias por linguagem e algoritmo.}
    \label{tab:sloc}
    \resizebox{0.7\textwidth}{!}{%
        \begin{tabular}{c|c|c}
            \hline
            \textbf{Linguagem} & \textbf{Algoritmo Exato} & \textbf{Algoritmo Heurístico} \\
            \hline
            C          & 71 & 121 \\
            C\#        & 48 & 80 \\
            C++        & 52 & 69 \\
            Go         & 51 & 64 \\
            Java       & 40 & 60 \\
            JavaScript & 28 & 34 \\
            Kotlin     & 32 & 52 \\
            Python     & 31 & 33 \\
            Rust       & 50 & 82 \\
            TypeScript & 37 & 44 \\
            \hline
        \end{tabular}%
    }
\end{table}

\textbf{Conclusão parcial:} Linguagens como Python e JavaScript exigiram menos linhas de código, indicando maior expressividade. Já C e Rust demandaram implementações mais extensas, refletindo maior controle de baixo nível.

\subsection{Considerações Finais dos Resultados}

Os experimentos confirmam que:  
Linguagens compiladas (C, C++, Rust) apresentam melhor desempenho em tempo e uso de memória, reforçando sua eficiência em problemas computacionalmente intensivos.  
Linguagens interpretadas (Python, JavaScript, TypeScript) destacam-se pela simplicidade de implementação, mas apresentam desempenho inferior em grandes datasets.  
O algoritmo heurístico mostrou-se uma alternativa altamente eficiente, viabilizando soluções próximas ao ótimo em frações do tempo exigido pelo algoritmo exato.  
O consumo de CPU e memória variou conforme o runtime da linguagem, evidenciando os custos adicionais de máquinas virtuais (Java, Kotlin) e interpretadores.  

Esses resultados fornecem a base empírica para a discussão, evidenciando os trade-offs entre desempenho, consumo de recursos e complexidade de implementação nas diferentes linguagens e algoritmos.

% REFERÊNCIAS
\bibliographystyle{abntex2-alf}
\bibliography{Bibliografia}

\end{document}
